{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import os\n",
       "\n",
       "import keras\n",
       "import tensorflow as tf\n",
       "\n",
       "from scipy import stats\n",
       "from sklearn import metrics\n",
       "\n",
       "from tqdm.notebook import tqdm\n",
       "from typing import Sequence\n",
       "\n",
       "from activations import ordinal_softmax\n",
       "from datautils import load_customer_level_csv\n",
       "from metrics import cumulative_true, gini_from_gain\n",
       "from utils import dnn_split\n",
       "\n",
       "from layers import CoralOrdinal\n",
       "from loss import OrdinalCrossEntropy"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 1 - Read Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "CATEGORICAL_FEATURES = ['chain', 'dept', 'category', 'brand', 'productmeasure']\n",
       "NUMERIC_FEATURES = ['log_calibration_value']\n",
       "ALL_FEATURES = CATEGORICAL_FEATURES + NUMERIC_FEATURES"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "COMPANY = 10000\n",
       "customer_level_data =  load_customer_level_csv(COMPANY)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/html": [
          "<div>\n",
          "<style scoped>\n",
          "    .dataframe tbody tr th:only-of-type {\n",
          "        vertical-align: middle;\n",
          "    }\n",
          "\n",
          "    .dataframe tbody tr th {\n",
          "        vertical-align: top;\n",
          "    }\n",
          "\n",
          "    .dataframe thead th {\n",
          "        text-align: right;\n",
          "    }\n",
          "</style>\n",
          "<table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          "    <tr style=\"text-align: right;\">\n",
          "      <th></th>\n",
          "      <th>id</th>\n",
          "      <th>calibration_value</th>\n",
          "      <th>chain</th>\n",
          "      <th>dept</th>\n",
          "      <th>category</th>\n",
          "      <th>brand</th>\n",
          "      <th>productmeasure</th>\n",
          "      <th>holdout_value</th>\n",
          "      <th>log_calibration_value</th>\n",
          "      <th>label</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <th>0</th>\n",
          "      <td>86246</td>\n",
          "      <td>0.69</td>\n",
          "      <td>205</td>\n",
          "      <td>97</td>\n",
          "      <td>9753</td>\n",
          "      <td>0</td>\n",
          "      <td>CT</td>\n",
          "      <td>322.730011</td>\n",
          "      <td>-0.371064</td>\n",
          "      <td>322.730011</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>1</th>\n",
          "      <td>86252</td>\n",
          "      <td>4.69</td>\n",
          "      <td>205</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>UNKNOWN</td>\n",
          "      <td>310.040009</td>\n",
          "      <td>1.545433</td>\n",
          "      <td>310.040009</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>2</th>\n",
          "      <td>12262064</td>\n",
          "      <td>0.99</td>\n",
          "      <td>95</td>\n",
          "      <td>97</td>\n",
          "      <td>9753</td>\n",
          "      <td>0</td>\n",
          "      <td>CT</td>\n",
          "      <td>11.730000</td>\n",
          "      <td>-0.010050</td>\n",
          "      <td>11.730000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>3</th>\n",
          "      <td>12277270</td>\n",
          "      <td>1.99</td>\n",
          "      <td>95</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>UNKNOWN</td>\n",
          "      <td>139.270004</td>\n",
          "      <td>0.688135</td>\n",
          "      <td>139.270004</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>4</th>\n",
          "      <td>12332190</td>\n",
          "      <td>1.00</td>\n",
          "      <td>95</td>\n",
          "      <td>97</td>\n",
          "      <td>9753</td>\n",
          "      <td>0</td>\n",
          "      <td>CT</td>\n",
          "      <td>11.720000</td>\n",
          "      <td>0.000000</td>\n",
          "      <td>11.720000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>5</th>\n",
          "      <td>12524696</td>\n",
          "      <td>0.20</td>\n",
          "      <td>4</td>\n",
          "      <td>99</td>\n",
          "      <td>9908</td>\n",
          "      <td>33170</td>\n",
          "      <td>OZ</td>\n",
          "      <td>8.070000</td>\n",
          "      <td>-1.609438</td>\n",
          "      <td>8.070000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>6</th>\n",
          "      <td>12682470</td>\n",
          "      <td>2.99</td>\n",
          "      <td>18</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>UNKNOWN</td>\n",
          "      <td>0.990000</td>\n",
          "      <td>1.095273</td>\n",
          "      <td>0.990000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>7</th>\n",
          "      <td>12996040</td>\n",
          "      <td>1.99</td>\n",
          "      <td>15</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "      <td>UNKNOWN</td>\n",
          "      <td>49.509998</td>\n",
          "      <td>0.688135</td>\n",
          "      <td>49.509998</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>8</th>\n",
          "      <td>13074629</td>\n",
          "      <td>1.25</td>\n",
          "      <td>14</td>\n",
          "      <td>97</td>\n",
          "      <td>9753</td>\n",
          "      <td>0</td>\n",
          "      <td>CT</td>\n",
          "      <td>17.150000</td>\n",
          "      <td>0.223144</td>\n",
          "      <td>17.150000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>9</th>\n",
          "      <td>13089312</td>\n",
          "      <td>2.00</td>\n",
          "      <td>15</td>\n",
          "      <td>97</td>\n",
          "      <td>9753</td>\n",
          "      <td>0</td>\n",
          "      <td>CT</td>\n",
          "      <td>30.240000</td>\n",
          "      <td>0.693147</td>\n",
          "      <td>30.240000</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table>\n",
          "</div>"
         ],
         "text/plain": [
          "         id  calibration_value chain dept category  brand productmeasure  \\\n",
          "0     86246               0.69   205   97     9753      0             CT   \n",
          "1     86252               4.69   205    0        0      0        UNKNOWN   \n",
          "2  12262064               0.99    95   97     9753      0             CT   \n",
          "3  12277270               1.99    95    0        0      0        UNKNOWN   \n",
          "4  12332190               1.00    95   97     9753      0             CT   \n",
          "5  12524696               0.20     4   99     9908  33170             OZ   \n",
          "6  12682470               2.99    18    0        0      0        UNKNOWN   \n",
          "7  12996040               1.99    15    0        0      0        UNKNOWN   \n",
          "8  13074629               1.25    14   97     9753      0             CT   \n",
          "9  13089312               2.00    15   97     9753      0             CT   \n",
          "\n",
          "   holdout_value  log_calibration_value       label  \n",
          "0     322.730011              -0.371064  322.730011  \n",
          "1     310.040009               1.545433  310.040009  \n",
          "2      11.730000              -0.010050   11.730000  \n",
          "3     139.270004               0.688135  139.270004  \n",
          "4      11.720000               0.000000   11.720000  \n",
          "5       8.070000              -1.609438    8.070000  \n",
          "6       0.990000               1.095273    0.990000  \n",
          "7      49.509998               0.688135   49.509998  \n",
          "8      17.150000               0.223144   17.150000  \n",
          "9      30.240000               0.693147   30.240000  "
         ]
        },
        "execution_count": 4,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "customer_level_data.head(10)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 2 - Split label into pre-defined distributions"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "12\n"
        ]
       }
      ],
      "source": [
       "bins = [-0.001, 0.5, 1.0, 2, 5, 10, 25, 50, 100, 1000, 10000, 100_000, 2062412.0] # <- predefined buckets\n",
       "keepbins = pd.cut(customer_level_data['label'], bins=bins, duplicates='drop').cat.categories.tolist()\n",
       "print(len(keepbins))\n",
       "customer_level_data['label_bucket'] = pd.cut(\n",
       "    customer_level_data['label'],\n",
       "    bins=bins,\n",
       "    retbins = True,\n",
       "    include_lowest = True,\n",
       "    labels = range(len(keepbins)),\n",
       "    duplicates='drop')[0].values"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "NUM_DISTRIBUTIONS = 4 # <- number of distributions\n",
       "NUM_BUCKETS = len(keepbins) // NUM_DISTRIBUTIONS\n",
       "dct_buckets = {i: i%NUM_BUCKETS for i in range(len(keepbins))}\n",
       "dct_distributions = {i: i//NUM_BUCKETS for i in range(len(keepbins))}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{0: 0, 1: 1, 2: 2, 3: 0, 4: 1, 5: 2, 6: 0, 7: 1, 8: 2, 9: 0, 10: 1, 11: 2}"
         ]
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "dct_buckets"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3}"
         ]
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "dct_distributions"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "# Replace the labels according to distributions and buckets\n",
       "\n",
       "customer_level_data['label_distribution'] = customer_level_data['label_bucket']\n",
       "customer_level_data[\"label_distribution\"].replace(dct_distributions, inplace=True)\n",
       "customer_level_data[\"label_bucket\"].replace(dct_buckets, inplace=True)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 3- Train-Test Split"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "# Min-Max scaling is performed inside the train/test split function. \n",
       "# Min-Max is performed separately for each distribution-bucket pair"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 4 - Layers\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class SimpleDNN(tf.keras.layers.Layer):\n",
       "    def __init__(self, num_bins = 3):\n",
       "\n",
       "        super(SimpleDNN, self).__init__()\n",
       "        self.num_bins = num_bins\n",
       "\n",
       "        self.dropout1 = tf.keras.layers.Dropout(0.1)\n",
       "        self.fc1 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
       "        self.fc2 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
       "        self.fc3 = tf.keras.layers.Dense(num_bins)\n",
       "    \n",
       "    def call(self, x):\n",
       "        x = self.fc1(x)\n",
       "        x = self.dropout1(x)\n",
       "        x = self.fc2(x)\n",
       "        prob = self.fc3(x)\n",
       "        return prob\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class CoralDNN(tf.keras.layers.Layer):\n",
       "    def __init__(self, num_bins = 3):\n",
       "\n",
       "        super(CoralDNN, self).__init__()\n",
       "        self.num_bins = num_bins\n",
       "\n",
       "        self.fc1 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
       "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
       "        self.fc2 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
       "        self.coral = CoralOrdinal(num_bins)\n",
       "    \n",
       "    def call(self, x):\n",
       "        x = self.fc1(x)\n",
       "        x = self.dropout(x)\n",
       "        x = self.fc2(x)\n",
       "        prob = self.coral(x)\n",
       "        return prob\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "### 4-1 Distribution Segmentation Module (DSM)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class DSM(tf.keras.layers.Layer):\n",
       "\n",
       "    def __init__(self, num_distributions=2):\n",
       "        super(DSM, self).__init__()\n",
       "\n",
       "        # predict distribution class\n",
       "        self.dct = SimpleDNN(num_bins=num_distributions)\n",
       "        \n",
       "        # predict distribution ordinality\n",
       "        self.dot = CoralDNN(num_bins=num_distributions)\n",
       "\n",
       "    def call(self, x, training=True):\n",
       "        dct = self.dct(x)\n",
       "        dot = self.dot(x)\n",
       "        return {\n",
       "            'pred_dct': dct,\n",
       "            'pred_dot': dot\n",
       "        }     "
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "### 4-2 Sub-Distribution modeling Module (SDM)\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class SDM(tf.keras.layers.Layer):\n",
       "    def __init__(self, num_buckets=2):\n",
       "\n",
       "        super(SDM, self).__init__()\n",
       "        # predict bucket class\n",
       "        self.bct = SimpleDNN(num_bins=num_buckets)\n",
       "        \n",
       "        # predict bucket ordinality\n",
       "#         self.bot = SimpleDNN(num_bins=num_buckets)\n",
       "        self.bot = CoralDNN(num_bins=num_buckets)\n",
       "\n",
       "        # predict minmax scaled label\n",
       "        self.deep_model = tf.keras.Sequential([tf.keras.layers.Dense(32, activation=\"relu\"),\n",
       "                                               tf.keras.layers.Dense(num_buckets, activation='sigmoid')])\n",
       "\n",
       "    def call(self, x, training=True):\n",
       "        bct = self.bct(x)\n",
       "        bot = self.bot(x)\n",
       "        y_pred = self.deep_model(x, training=training)\n",
       "        return {\n",
       "            'pred_bct': bct,\n",
       "            'pred_bot': bot,\n",
       "            'pred_label': y_pred\n",
       "        }"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 4-3 Multi Distribution Multi Experts Module (MDME)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class MDME(tf.keras.Model):\n",
       "    def __init__(self, ltvmodel, *args, **kwargs):\n",
       "\n",
       "        super().__init__()\n",
       "        self.ltvmodel = ltvmodel\n",
       "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
       "    \n",
       "    def compile(self, optimizer, loss_fn):\n",
       "        super().compile(optimizer)\n",
       "        self.optimizer = optimizer\n",
       "        self.loss_fn = loss_fn\n",
       "    \n",
       "    def call(self, x, training=False):\n",
       "        return self.ltvmodel(x, training=training)\n",
       "    \n",
       "    def predict(self, x, training=False):\n",
       "        y = self(x, training=training)\n",
       "        return y\n",
       "\n",
       "    @property\n",
       "    def metrics(self):\n",
       "        # We list our `Metric` objects here so that `reset_states()` can be\n",
       "        # called automatically at the start of each epoch\n",
       "        # or at the start of `evaluate()`.\n",
       "        # If you don't implement this property, you have to call\n",
       "        # `reset_states()` yourself at the time of your choosing.\n",
       "        return [self.loss_tracker]\n",
       "    \n",
       "    def train_step(self, data):\n",
       "        x, y = data\n",
       "        with tf.GradientTape() as tape:\n",
       "            y_pred = self(x, training=True)\n",
       "            loss_value = self.loss_fn(y, y_pred)\n",
       "        grads = tape.gradient(loss_value, self.trainable_variables)\n",
       "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
       "        self.loss_tracker.update_state(loss_value)\n",
       "        return {\"loss\": self.loss_tracker.result()}\n",
       "    \n",
       "    def test_step(self, data):\n",
       "        x, y = data\n",
       "        y_pred = self(x, training=False)\n",
       "        loss_value = self.loss_fn(y, y_pred)\n",
       "        \n",
       "        self.loss_tracker.update_state(loss_value)\n",
       "        # Return a dict mapping metric names to current value.\n",
       "        # Note that it will include the loss (tracked in self.metrics).\n",
       "        return {\"loss_val\": self.loss_tracker.result()}"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 4-4 Defining loss "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "class MDMELoss(tf.keras.losses.Loss):\n",
       "\n",
       "    # initialize instance attributes\n",
       "    def __init__(self):\n",
       "        super(MDMELoss, self).__init__()\n",
       "        \n",
       "    # Compute loss\n",
       "    def call(self, y_true, y_pred):\n",
       "        \n",
       "        losses = []\n",
       "        \n",
       "        y_true_dct = y_true['label_distribution']\n",
       "        y_true_dot = y_true['label_ordinality']\n",
       "        y_true_bucket_bct = y_true['bucket_distribution']\n",
       "        y_true_bucket_bot = y_true['bucket_ordinality']\n",
       "        y_true_bucket_label_minmax = y_true['label_minmax']\n",
       "        \n",
       "        y_pred_dct = y_pred['dsm']['pred_dct']        \n",
       "        y_pred_dot = y_pred['dsm']['pred_dot'] \n",
       "        \n",
       "        y_pred_bcts = []\n",
       "        y_pred_bots = []\n",
       "        y_pred_labels = []\n",
       "\n",
       "        for i in range(NUM_DISTRIBUTIONS):\n",
       "            y_pred_bcts.append(y_pred[f\"sdm_{i}\"]['pred_bct'])\n",
       "            y_pred_bots.append(y_pred[f\"sdm_{i}\"]['pred_bot'])\n",
       "            y_pred_labels.append(y_pred[f\"sdm_{i}\"]['pred_label'])\n",
       "        y_pred_bcts = tf.stack(y_pred_bcts, axis=1)\n",
       "        y_pred_bots = tf.stack(y_pred_bots, axis=1)\n",
       "        y_pred_labels = tf.stack(y_pred_labels, axis=1)\n",
       "        \n",
       "\n",
       "        predicted_distribution_label = tf.argmax(y_pred_dct, axis=1)\n",
       "        y_pred_bct = tf.gather(y_pred_bcts, predicted_distribution_label, batch_dims=1)\n",
       "        y_pred_bot = tf.gather(y_pred_bots, predicted_distribution_label, batch_dims=1)\n",
       "        y_pred_label = tf.gather(y_pred_labels, predicted_distribution_label, batch_dims=1)\n",
       "\n",
       "        # Distribution classification loss\n",
       "        loss_dct = tf.keras.losses.SparseCategoricalCrossentropy(\n",
       "            from_logits=True, reduction='sum_over_batch_size')(y_true_dct, y_pred_dct)\n",
       "        losses.append(loss_dct)\n",
       "\n",
       "        # Distribution ordinal regression loss\n",
       "        loss_dot = OrdinalCrossEntropy(NUM_DISTRIBUTIONS, reduction='sum_over_batch_size')(y_true_dot, y_pred_dot)\n",
       "        losses.append(loss_dot)\n",
       "\n",
       "        T = 0.1\n",
       "        soft_teacher = ordinal_softmax(y_pred_dot / T)  # Teacher soft labels\n",
       "        soft_student = tf.nn.softmax(y_pred_dct / T)  # Teacher soft labels\n",
       "        loss_soft_labels = tf.keras.losses.KLDivergence(reduction='sum_over_batch_size')(tf.stop_gradient(soft_teacher), soft_student)\n",
       "#         loss_soft_labels = tf.keras.losses.CategoricalCrossentropy(\n",
       "#             from_logits=False,\n",
       "#             reduction='sum_over_batch_size')(tf.stop_gradient(soft_teacher), soft_student)\n",
       "        losses.append(0.5*loss_soft_labels)\n",
       "\n",
       "        # Bucket classification loss\n",
       "        loss_bucket_bct = tf.keras.losses.SparseCategoricalCrossentropy(\n",
       "            from_logits=True, \n",
       "            reduction='sum_over_batch_size')(y_true_bucket_bct, y_pred_bct)\n",
       "        losses.append(loss_bucket_bct)\n",
       "\n",
       "        # Bucket ordinal regression loss\n",
       "        loss_bucket_bot = OrdinalCrossEntropy(NUM_BUCKETS, reduction='sum_over_batch_size')(y_true_bucket_bot, y_pred_bot)\n",
       "        losses.append(loss_bucket_bot)\n",
       "\n",
       "        # Soft label loss\n",
       "        T = 0.1\n",
       "        soft_teacher = ordinal_softmax(y_pred_bot / T)  # Teacher soft labels\n",
       "        soft_student = tf.nn.softmax(y_pred_bct / T)  # Teacher soft labels\n",
       "        loss_soft_labels_bucket = tf.keras.losses.KLDivergence(\n",
       "            reduction='sum_over_batch_size')(tf.stop_gradient(soft_teacher), soft_student)\n",
       "#         loss_soft_labels_bucket = tf.keras.losses.CategoricalCrossentropy(\n",
       "#             from_logits=False,\n",
       "#             reduction='sum_over_batch_size')(tf.stop_gradient(soft_teacher), soft_student)\n",
       "        losses.append(0.5*loss_soft_labels_bucket)\n",
       "\n",
       "        # MSE Loss\n",
       "        predicted_bucket_label = tf.argmax(y_pred_bct, axis=-1)\n",
       "        y_pred_labels = tf.gather(y_pred_label, predicted_bucket_label, batch_dims=1)\n",
       "        loss_mse = tf.keras.losses.MeanSquaredError(\n",
       "            reduction='sum_over_batch_size')(y_true_bucket_label_minmax, y_pred_labels)\n",
       "        losses.append(loss_mse)\n",
       "\n",
       "        return tf.reduce_sum(losses)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 5 - Building Input"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "def embedding_dim(x):\n",
       "    return int(x**.25) + 1\n",
       "\n",
       "def embedding_layer(vocab_size):\n",
       "    return tf.keras.Sequential([\n",
       "        tf.keras.layers.Embedding(input_dim=vocab_size,\n",
       "#                                   output_dim=embedding_dim(vocab_size),\n",
       "                                  output_dim = 5,\n",
       "                                  input_length=1),\n",
       "        tf.keras.layers.Flatten(),\n",
       "    ])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "numeric_input = tf.keras.layers.Input(shape=(len(NUMERIC_FEATURES),), name='numeric')\n",
       "embedding_inputs = [\n",
       "    tf.keras.layers.Input(shape=(1,), name=key, dtype=np.int64)\n",
       "    for key in CATEGORICAL_FEATURES\n",
       "]\n",
       "embedding_outputs = [\n",
       "    embedding_layer(vocab_size=customer_level_data[key].nunique())(input)\n",
       "    for key, input in zip(CATEGORICAL_FEATURES, embedding_inputs)\n",
       "]\n",
       "deep_input = tf.keras.layers.concatenate([numeric_input] + embedding_outputs)\n",
       "\n",
       "dsm_m = DSM(num_distributions=NUM_DISTRIBUTIONS)\n",
       "\n",
       "outputs = {}\n",
       "for i in range(NUM_DISTRIBUTIONS):\n",
       "    sdm = SDM(num_buckets=NUM_BUCKETS)\n",
       "    outputs[f\"sdm_{i}\"] = sdm(deep_input)\n",
       "        \n",
       "\n",
       "outputs['dsm'] = dsm_m(deep_input) \n",
       "\n",
       "ltvmodel = tf.keras.Model(inputs=[numeric_input] + embedding_inputs, outputs=outputs)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Initial Learning Rate: 0.0010000000474974513\n"
        ]
       }
      ],
      "source": [
       "LEARNING_RATE = 1e-3\n",
       "callbacks = [\n",
       "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss_val', min_lr=1e-6),\n",
       "    tf.keras.callbacks.EarlyStopping(monitor='val_loss_val', patience=10),\n",
       "]\n",
       "loss = MDMELoss()\n",
       "model = MDME(ltvmodel)\n",
       "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss_fn=loss)\n",
       "print(f\"Initial Learning Rate: {model.optimizer.lr.numpy()}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "x_train, x_eval, y_train, y_eval, y0_eval = dnn_split(customer_level_data)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Epoch 1/400\n",
         "184/184 - 8s - loss: 5.8276 - val_loss_val: 5.5189 - lr: 0.0010 - 8s/epoch - 41ms/step\n",
         "Epoch 2/400\n",
         "184/184 - 2s - loss: 5.4451 - val_loss_val: 5.3192 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 3/400\n",
         "184/184 - 2s - loss: 5.2764 - val_loss_val: 5.1975 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 4/400\n",
         "184/184 - 2s - loss: 5.1480 - val_loss_val: 5.0769 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 5/400\n",
         "184/184 - 2s - loss: 5.0352 - val_loss_val: 4.9796 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 6/400\n",
         "184/184 - 2s - loss: 4.9484 - val_loss_val: 4.9154 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 7/400\n",
         "184/184 - 2s - loss: 4.8866 - val_loss_val: 4.8614 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 8/400\n",
         "184/184 - 2s - loss: 4.8360 - val_loss_val: 4.8195 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 9/400\n",
         "184/184 - 2s - loss: 4.7990 - val_loss_val: 4.7848 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 10/400\n",
         "184/184 - 2s - loss: 4.7660 - val_loss_val: 4.7566 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 11/400\n",
         "184/184 - 2s - loss: 4.7384 - val_loss_val: 4.7312 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 12/400\n",
         "184/184 - 2s - loss: 4.7169 - val_loss_val: 4.7162 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 13/400\n",
         "184/184 - 2s - loss: 4.6977 - val_loss_val: 4.6979 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 14/400\n",
         "184/184 - 2s - loss: 4.6809 - val_loss_val: 4.6840 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 15/400\n",
         "184/184 - 2s - loss: 4.6674 - val_loss_val: 4.6688 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 16/400\n",
         "184/184 - 2s - loss: 4.6558 - val_loss_val: 4.6577 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 17/400\n",
         "184/184 - 2s - loss: 4.6455 - val_loss_val: 4.6480 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 18/400\n",
         "184/184 - 2s - loss: 4.6369 - val_loss_val: 4.6429 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 19/400\n",
         "184/184 - 2s - loss: 4.6306 - val_loss_val: 4.6393 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 20/400\n",
         "184/184 - 2s - loss: 4.6236 - val_loss_val: 4.6297 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 21/400\n",
         "184/184 - 2s - loss: 4.6177 - val_loss_val: 4.6281 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 22/400\n",
         "184/184 - 2s - loss: 4.6125 - val_loss_val: 4.6205 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 23/400\n",
         "184/184 - 2s - loss: 4.6101 - val_loss_val: 4.6162 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 24/400\n",
         "184/184 - 2s - loss: 4.6056 - val_loss_val: 4.6106 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 25/400\n",
         "184/184 - 2s - loss: 4.6020 - val_loss_val: 4.6083 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 26/400\n",
         "184/184 - 2s - loss: 4.6000 - val_loss_val: 4.6082 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 27/400\n",
         "184/184 - 2s - loss: 4.5973 - val_loss_val: 4.6057 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 28/400\n",
         "184/184 - 2s - loss: 4.5956 - val_loss_val: 4.6046 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 29/400\n",
         "184/184 - 2s - loss: 4.5928 - val_loss_val: 4.5999 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 30/400\n",
         "184/184 - 2s - loss: 4.5918 - val_loss_val: 4.6005 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 31/400\n",
         "184/184 - 2s - loss: 4.5916 - val_loss_val: 4.6024 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 32/400\n",
         "184/184 - 2s - loss: 4.5895 - val_loss_val: 4.6006 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 33/400\n",
         "184/184 - 2s - loss: 4.5878 - val_loss_val: 4.5983 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 34/400\n",
         "184/184 - 2s - loss: 4.5870 - val_loss_val: 4.5986 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 35/400\n",
         "184/184 - 2s - loss: 4.5857 - val_loss_val: 4.5987 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 36/400\n",
         "184/184 - 2s - loss: 4.5835 - val_loss_val: 4.5948 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 37/400\n",
         "184/184 - 2s - loss: 4.5843 - val_loss_val: 4.5949 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 38/400\n",
         "184/184 - 2s - loss: 4.5844 - val_loss_val: 4.5974 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 39/400\n",
         "184/184 - 2s - loss: 4.5826 - val_loss_val: 4.5926 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 40/400\n",
         "184/184 - 2s - loss: 4.5826 - val_loss_val: 4.5938 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 41/400\n",
         "184/184 - 2s - loss: 4.5815 - val_loss_val: 4.5913 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 42/400\n",
         "184/184 - 2s - loss: 4.5801 - val_loss_val: 4.5924 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 43/400\n",
         "184/184 - 2s - loss: 4.5810 - val_loss_val: 4.5920 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 44/400\n",
         "184/184 - 2s - loss: 4.5794 - val_loss_val: 4.5912 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 45/400\n",
         "184/184 - 2s - loss: 4.5793 - val_loss_val: 4.5911 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 46/400\n",
         "184/184 - 2s - loss: 4.5786 - val_loss_val: 4.5879 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 47/400\n",
         "184/184 - 2s - loss: 4.5772 - val_loss_val: 4.5946 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 48/400\n",
         "184/184 - 2s - loss: 4.5787 - val_loss_val: 4.5919 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 49/400\n",
         "184/184 - 2s - loss: 4.5790 - val_loss_val: 4.5907 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 50/400\n",
         "184/184 - 2s - loss: 4.5787 - val_loss_val: 4.5910 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 51/400\n",
         "184/184 - 2s - loss: 4.5776 - val_loss_val: 4.5917 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 52/400\n",
         "184/184 - 2s - loss: 4.5760 - val_loss_val: 4.5916 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 53/400\n",
         "184/184 - 2s - loss: 4.5754 - val_loss_val: 4.5887 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 54/400\n",
         "184/184 - 2s - loss: 4.5786 - val_loss_val: 4.5954 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 55/400\n",
         "184/184 - 2s - loss: 4.5785 - val_loss_val: 4.5921 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 56/400\n",
         "184/184 - 2s - loss: 4.5756 - val_loss_val: 4.5863 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 57/400\n",
         "184/184 - 2s - loss: 4.5766 - val_loss_val: 4.5921 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 58/400\n",
         "184/184 - 2s - loss: 4.5756 - val_loss_val: 4.5916 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 59/400\n",
         "184/184 - 2s - loss: 4.5761 - val_loss_val: 4.5890 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 60/400\n",
         "184/184 - 2s - loss: 4.5763 - val_loss_val: 4.5877 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 61/400\n",
         "184/184 - 2s - loss: 4.5758 - val_loss_val: 4.5912 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 62/400\n",
         "184/184 - 2s - loss: 4.5738 - val_loss_val: 4.5891 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 63/400\n",
         "184/184 - 2s - loss: 4.5759 - val_loss_val: 4.5914 - lr: 0.0010 - 2s/epoch - 12ms/step\n",
         "Epoch 64/400\n",
         "184/184 - 2s - loss: 4.5740 - val_loss_val: 4.5878 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 65/400\n",
         "184/184 - 2s - loss: 4.5757 - val_loss_val: 4.5935 - lr: 0.0010 - 2s/epoch - 13ms/step\n",
         "Epoch 66/400\n",
         "184/184 - 2s - loss: 4.5736 - val_loss_val: 4.5896 - lr: 0.0010 - 2s/epoch - 12ms/step\n"
        ]
       }
      ],
      "source": [
       "history = model.fit(\n",
       "    x=x_train,\n",
       "    y=y_train,\n",
       "    batch_size=1024,\n",
       "    epochs=400,\n",
       "    verbose=2,\n",
       "    callbacks=callbacks,\n",
       "    validation_data=(x_eval, y_eval)).history"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "data": {
         "text/plain": [
          "<AxesSubplot:>"
         ]
        },
        "execution_count": 22,
        "metadata": {},
        "output_type": "execute_result"
       },
       {
        "data": {
         "image/png": "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\n",
         "text/plain": [
          "<Figure size 640x480 with 1 Axes>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "pd.DataFrame(history)[['loss', 'val_loss_val']][2:].plot()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 6 - Inference"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "logits = model.predict(x=x_eval)\n",
       "y_pred = []\n",
       "for i in range(logits['dsm']['pred_dct'].shape[0]):\n",
       "    item = logits['dsm']['pred_dct'][i]\n",
       "    distribution_label = tf.math.argmax(item).numpy()\n",
       "    bucket = logits[f\"sdm_{distribution_label}\"]['pred_bct'][i]\n",
       "    sigmas = logits[f\"sdm_{distribution_label}\"]['pred_label'][i]\n",
       "    bucket_label = tf.math.argmax(bucket).numpy()\n",
       "    idx = distribution_label * NUM_BUCKETS + bucket_label\n",
       "    pred = keepbins[idx].left + sigmas[bucket_label] * keepbins[idx].length\n",
       "    y_pred.append(pred.numpy())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "source": [
       "## 7 - Evaluation"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "data": {
         "text/html": [
          "<div>\n",
          "<style scoped>\n",
          "    .dataframe tbody tr th:only-of-type {\n",
          "        vertical-align: middle;\n",
          "    }\n",
          "\n",
          "    .dataframe tbody tr th {\n",
          "        vertical-align: top;\n",
          "    }\n",
          "\n",
          "    .dataframe thead th {\n",
          "        text-align: right;\n",
          "    }\n",
          "</style>\n",
          "<table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          "    <tr style=\"text-align: right;\">\n",
          "      <th></th>\n",
          "      <th>y_true</th>\n",
          "      <th>y_pred</th>\n",
          "      <th>label_distribution</th>\n",
          "      <th>bucket_distribution</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <th>69003</th>\n",
          "      <td>31.400000</td>\n",
          "      <td>6.975223</td>\n",
          "      <td>2</td>\n",
          "      <td>0</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>87546</th>\n",
          "      <td>0.990000</td>\n",
          "      <td>70.562073</td>\n",
          "      <td>0</td>\n",
          "      <td>1</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>174617</th>\n",
          "      <td>0.990000</td>\n",
          "      <td>0.173319</td>\n",
          "      <td>0</td>\n",
          "      <td>1</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>181104</th>\n",
          "      <td>48.330002</td>\n",
          "      <td>6.867325</td>\n",
          "      <td>2</td>\n",
          "      <td>0</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>7254</th>\n",
          "      <td>1.300000</td>\n",
          "      <td>7.187225</td>\n",
          "      <td>0</td>\n",
          "      <td>2</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>229183</th>\n",
          "      <td>9.450000</td>\n",
          "      <td>6.961293</td>\n",
          "      <td>1</td>\n",
          "      <td>1</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>29027</th>\n",
          "      <td>20.750000</td>\n",
          "      <td>6.910069</td>\n",
          "      <td>1</td>\n",
          "      <td>2</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>135880</th>\n",
          "      <td>43.200001</td>\n",
          "      <td>7.004164</td>\n",
          "      <td>2</td>\n",
          "      <td>0</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>115346</th>\n",
          "      <td>15.000000</td>\n",
          "      <td>7.027415</td>\n",
          "      <td>1</td>\n",
          "      <td>2</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>153886</th>\n",
          "      <td>0.000000</td>\n",
          "      <td>6.984661</td>\n",
          "      <td>0</td>\n",
          "      <td>0</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table>\n",
          "</div>"
         ],
         "text/plain": [
          "           y_true     y_pred  label_distribution  bucket_distribution\n",
          "69003   31.400000   6.975223                   2                    0\n",
          "87546    0.990000  70.562073                   0                    1\n",
          "174617   0.990000   0.173319                   0                    1\n",
          "181104  48.330002   6.867325                   2                    0\n",
          "7254     1.300000   7.187225                   0                    2\n",
          "229183   9.450000   6.961293                   1                    1\n",
          "29027   20.750000   6.910069                   1                    2\n",
          "135880  43.200001   7.004164                   2                    0\n",
          "115346  15.000000   7.027415                   1                    2\n",
          "153886   0.000000   6.984661                   0                    0"
         ]
        },
        "execution_count": 24,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "df_pred = pd.DataFrame({\n",
       "    'y_true': y_eval['label'],\n",
       "    'y_pred': y_pred,\n",
       "    'label_distribution': y_eval['label_distribution'],\n",
       "    'bucket_distribution': y_eval['bucket_distribution'],\n",
       "})\n",
       "df_pred.head(10)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Spearman correlation: 0.1933827230662824\n",
         "Only positive samples spearman correlation: 0.10927816691307894\n"
        ]
       }
      ],
      "source": [
       "def spearmanr(x1: Sequence[float], x2: Sequence[float]) -> float:\n",
       "  \"\"\"Calculates spearmanr rank correlation coefficient.\n",
       "\n",
       "  See https://docs.scipy.org/doc/scipy/reference/stats.html.\n",
       "\n",
       "  Args:\n",
       "    x1: 1D array_like.\n",
       "    x2: 1D array_like.\n",
       "\n",
       "  Returns:\n",
       "    correlation: float.\n",
       "  \"\"\"\n",
       "  return stats.spearmanr(x1, x2, nan_policy='raise')[0]\n",
       "\n",
       "\n",
       "spearman_corr = spearmanr(df_pred['y_true'], df_pred['y_pred'])\n",
       "print('Spearman correlation:', spearman_corr)\n",
       "\n",
       "positive_index = df_pred['y_true'] > 0\n",
       "spearman_corr_pos = spearmanr(df_pred.loc[positive_index, 'y_true'], df_pred.loc[positive_index, 'y_pred'])\n",
       "print('Only positive samples spearman correlation:', spearman_corr_pos)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [],
      "source": [
       "gain = pd.DataFrame({\n",
       "    'lorenz': cumulative_true(df_pred['y_true'], df_pred['y_true']),\n",
       "    'baseline': cumulative_true(df_pred['y_true'], y0_eval),\n",
       "    'model': cumulative_true(df_pred['y_true'], df_pred['y_pred']),\n",
       "})\n",
       "num_customers = np.float32(gain.shape[0])\n",
       "gain['cumulative_customer'] = (np.arange(num_customers) + 1.) / num_customers"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "data": {
         "text/html": [
          "<div>\n",
          "<style scoped>\n",
          "    .dataframe tbody tr th:only-of-type {\n",
          "        vertical-align: middle;\n",
          "    }\n",
          "\n",
          "    .dataframe tbody tr th {\n",
          "        vertical-align: top;\n",
          "    }\n",
          "\n",
          "    .dataframe thead th {\n",
          "        text-align: right;\n",
          "    }\n",
          "</style>\n",
          "<table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          "    <tr style=\"text-align: right;\">\n",
          "      <th></th>\n",
          "      <th>raw</th>\n",
          "      <th>normalized</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <th>lorenz</th>\n",
          "      <td>0.891897</td>\n",
          "      <td>1.000000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>baseline</th>\n",
          "      <td>0.725321</td>\n",
          "      <td>0.813235</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <th>model</th>\n",
          "      <td>0.696189</td>\n",
          "      <td>0.780571</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table>\n",
          "</div>"
         ],
         "text/plain": [
          "               raw  normalized\n",
          "lorenz    0.891897    1.000000\n",
          "baseline  0.725321    0.813235\n",
          "model     0.696189    0.780571"
         ]
        },
        "execution_count": 27,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "gini = gini_from_gain(gain[['lorenz', 'baseline', 'model']])\n",
       "gini"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
       "vscode": {
        "languageId": "plaintext"
       }
      },
      "outputs": [
       {
        "data": {
         "text/plain": [
          "60.906475"
         ]
        },
        "execution_count": 28,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "metrics.mean_absolute_error(df_pred['y_true'], df_pred['y_pred'])"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   